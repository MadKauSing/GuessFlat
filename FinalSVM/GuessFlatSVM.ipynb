{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS put all here\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#tf imports for reading file\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#extras\n",
    "print(tf.__version__)\n",
    "import pathlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to image dataset\n",
    "spec_path = '../content/spectrograms6sec'\n",
    "chroma_path='../content/chroma6sec'\n",
    "test_path='../content/testset'\n",
    "genre_list=os.listdir(spec_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('../content/chroma6secnew')\n",
    "# dest_path='../content/chroma6secnew'\n",
    "\n",
    "# for genre in genre_list:\n",
    "#   os.mkdir(f'../content/chroma6secnew/{genre}')\n",
    "\n",
    "\n",
    "\n",
    "# #no of samples per class\n",
    "# n=3000\n",
    "# cnt=0\n",
    "\n",
    "# random.seed(123)\n",
    "\n",
    "# for genre in genre_list:\n",
    "#   genre_path=os.path.join(chroma_path,genre)\n",
    "#   dest_genre_path=os.path.join(dest_path,genre)\n",
    "\n",
    "#   #shuffling and selecting 3000 samples\n",
    "#   genre_songs=os.listdir(genre_path)\n",
    "#   random.shuffle(genre_songs)\n",
    "#   selected_spec=genre_songs[:n]\n",
    "  \n",
    "#   for song in selected_spec:\n",
    "#       source=os.path.join(genre_path,song)\n",
    "#       dest=os.path.join(dest_genre_path,song)\n",
    "#       d= shutil.copyfile(source, dest)\n",
    "\n",
    "\n",
    "# EQUALISING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data_sets\n",
    "spec_path='../content/spectrograms6secnew/'\n",
    "chroma_path='../content/chroma6secnew/'\n",
    "\n",
    "data_dir_spec=pathlib.Path(spec_path)\n",
    "data_dir_chroma=pathlib.Path(chroma_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding dataset\n",
    "batch_size=64\n",
    "image_height=100\n",
    "image_width=200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 10 classes.\n",
      "Using 24000 files for training.\n",
      "Found 30000 files belonging to 10 classes.\n",
      "Using 24000 files for training.\n"
     ]
    }
   ],
   "source": [
    "#training dataset spectrograms\n",
    "train_ds_spec = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_spec,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# training dataset chromagrams\n",
    "\n",
    "train_ds_chroma = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_chroma,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 10 classes.\n",
      "Using 6000 files for validation.\n",
      "Found 30000 files belonging to 10 classes.\n",
      "Using 6000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds_spec = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_spec,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds_chroma = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_chroma,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 200, 3)\n",
      "(64,)\n",
      "(64, 100, 200, 3)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds_spec:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n",
    "for image_batch, labels_batch in train_ds_chroma:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds_spec.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#\n",
    "train_ds_spec = train_ds_spec.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds_spec = val_ds_spec.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "#\n",
    "train_ds_chroma = train_ds_chroma.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds_chroma = val_ds_chroma.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(\n",
    "    train_ds_spec,\n",
    "    validation_data=val_ds_spec,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ai_ml_nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75f149aabefc45f596bad3ecd1cce999665dc47c609d2b6ed1c0c06088326543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
