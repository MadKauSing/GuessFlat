{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "# from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.models import Model\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "#IMPORTS put all here\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#tf imports for reading file\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#extras\n",
    "print(tf.__version__)\n",
    "import pathlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setup\n",
    "\n",
    "# imgs_path = \"../input/style/\"\n",
    "imgs_model_width, imgs_model_height = 224, 224\n",
    "\n",
    "nb_closest_images = 5 # number of most similar images to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../content/new/spectrograms6secnew')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_path='../content/new/spectrograms6secnew'\n",
    "\n",
    "data_dir=pathlib.Path(dest_path)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding dataset\n",
    "batch_size=64\n",
    "image_height=75\n",
    "image_width=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29990 files belonging to 10 classes.\n",
      "Using 23992 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29990 files belonging to 10 classes.\n",
      "Using 5998 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bhojpuri_pop', 'carnatic', 'classic_bollywood', 'desi_pop', 'ghazal', 'hindustani_classical', 'indian_indie', 'punjabi_hip_hop', 'sufi', 'tamil_pop']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 263s 678ms/step - loss: 2.0133 - accuracy: 0.3692 - val_loss: 3.1283 - val_accuracy: 0.1664\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 239s 628ms/step - loss: 1.4864 - accuracy: 0.4897 - val_loss: 1.9156 - val_accuracy: 0.3740\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 246s 643ms/step - loss: 1.3301 - accuracy: 0.5364 - val_loss: 1.6213 - val_accuracy: 0.4533\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 239s 627ms/step - loss: 1.2478 - accuracy: 0.5646 - val_loss: 1.3911 - val_accuracy: 0.5165\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 236s 618ms/step - loss: 1.1953 - accuracy: 0.5823 - val_loss: 1.6869 - val_accuracy: 0.4520\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(class_names)\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Rescaling(1./255))\n",
    "model.add(tf.keras.layers.Input(shape=(75, 150, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(16, 3, strides=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile('adam',loss=tf.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "\n",
    "epochs=5\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: .\\models\\models\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32md:\\MI project\\GuessFlat\\Recommender\\recommender.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MI%20project/GuessFlat/Recommender/recommender.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MI%20project/GuessFlat/Recommender/recommender.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mmodels\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mmodels\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:115\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot parse file \u001b[39m\u001b[39m{\u001b[39;00mpath_to_pbtxt\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSavedModel file does not exist at: \u001b[39m\u001b[39m{\u001b[39;00mexport_dir\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msep\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mconstants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[39m}\u001b[39;00m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconstants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: .\\models\\models\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\".\\models\\models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../content/new/spectrograms6secnew\\sufi\\A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina1.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[8.2908067e-20 7.4943743e-21 9.9994600e-01 8.3869644e-21 1.9165328e-19\n",
      "  5.4051899e-05 9.2827226e-18 4.7357246e-27 1.2696037e-36 5.8324525e-17]]\n",
      "2\n",
      "../content/new/spectrograms6secnew\\sufi\\A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina10.png\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[6.8197513e-20 7.5745607e-21 9.9993420e-01 7.4105358e-21 1.9626251e-19\n",
      "  6.5766610e-05 8.6627499e-18 4.5716893e-27 1.1676563e-36 5.0065844e-17]]\n",
      "2\n",
      "../content/new/spectrograms6secnew\\sufi\\A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina12.png\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[6.2310423e-20 7.7554822e-21 9.9993730e-01 6.9970925e-21 1.7383173e-19\n",
      "  6.2718151e-05 8.0501457e-18 4.2413322e-27 1.0319195e-36 4.8569706e-17]]\n",
      "2\n",
      "../content/new/spectrograms6secnew\\sufi\\A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina13.png\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[7.6451709e-20 6.9539701e-21 9.9993134e-01 6.2629346e-21 1.4845687e-19\n",
      "  6.8715482e-05 6.8725710e-18 4.2969535e-27 1.0551602e-36 3.8335341e-17]]\n",
      "2\n",
      "../content/new/spectrograms6secnew\\sufi\\A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina14.png\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[7.0794524e-20 7.4554289e-21 9.9993896e-01 7.1700613e-21 1.7360803e-19\n",
      "  6.1021070e-05 8.6748945e-18 4.6424295e-27 1.1814079e-36 5.0814175e-17]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cnt = 0\n",
    "path = os.path.join(dest_path,'sufi')\n",
    "for images in os.listdir(path):\n",
    "    print(os.path.join(path,images))\n",
    "    img = cv2.imread(os.path.join(path,images))\n",
    "    img = tf.image.resize(img,(75,150))\n",
    "    yhat = model.predict(np.expand_dims(img/255.0,axis=0))\n",
    "    print(yhat)\n",
    "    print(yhat.argmax())\n",
    "    cnt+=1\n",
    "    if cnt == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941433396315041\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from scipy import spatial\n",
    "\n",
    "test_image1 = Image.open(\"../content/new/spectrograms6secnew\\sufi\\A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina14.png\")\n",
    "test_image2 = Image.open(\"../content/new/spectrograms6secnew\\sufi\\A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina10.png\")\n",
    "\n",
    "img_1 = test_image1.resize((100,200))\n",
    "img_2 = test_image2.resize((100,200))\n",
    "\n",
    "arr_1 = np.array(img_1)\n",
    "arr_2 = np.array(img_2)\n",
    "\n",
    "arr_1 = arr_1.flatten()\n",
    "arr_2 = arr_2.flatten()\n",
    "\n",
    "arr_1 = arr_1/255\n",
    "arr_2 = arr_2/255\n",
    "\n",
    "similarity = -1 * (spatial.distance.cosine(arr_1,arr_2) - 1)\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_array(image):\n",
    "    img = image.resize((100,200))\n",
    "    img_arr = np.array(img)\n",
    "    img_arr = img_arr.flatten()\n",
    "    img_arr = img_arr/255\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina1.png', 0.9884426057340217], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina10.png', 0.9941433396315041], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina12.png', 0.9946501562544591], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina13.png', 0.9947671280478219], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina14.png', 1], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina16.png', 0.9943340744466141], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina18.png', 0.9942302193022037], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina2.png', 0.9937414928944845], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina21.png', 0.9937744353109781], ['A.R. Rahman, Chinmayi, Murtuza Khan, Qadir Khan - Tere Bina26.png', 0.9934529220706868]]\n"
     ]
    }
   ],
   "source": [
    "compared_image = get_image_array(test_image1)\n",
    "similarity_images = []\n",
    "cnt = 0\n",
    "path = os.path.join(dest_path,'sufi')\n",
    "for images in os.listdir(path):\n",
    "    image_obj = Image.open(os.path.join(path,images))\n",
    "    \n",
    "    image2 = get_image_array(image_obj)\n",
    "    similarity = -1 * (spatial.distance.cosine(compared_image,image2) - 1)\n",
    "    image_name = images.split('\\\\')[-1]\n",
    "    similarity_images.append([image_name,similarity])\n",
    "    cnt+=1\n",
    "    if cnt == 10:\n",
    "        break\n",
    "\n",
    "print(similarity_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30d475033c0928b95234fbbc496e659fedb0f92ce88e1cb0d2d96ee86321ca81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
