{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import librosa\n",
    "import matplotlib\n",
    "import matplotlib as plt\n",
    "from IPython.display import Audio\n",
    "from tensorflow.keras.models import load_model\n",
    "import pathlib\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf ../content/testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path='testset/'\n",
    "\n",
    "genre_list=['bhojpuri_pop',\n",
    " 'carnatic',\n",
    " 'classic_bollywood',\n",
    " 'desi_pop',\n",
    " 'ghazal',\n",
    " 'hindustani_classical',\n",
    " 'indian_indie',\n",
    " 'punjabi_hip_hop',\n",
    " 'sufi',\n",
    " 'tamil_pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankush Raja - Dar kekra se ba14.png'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"../content/spectrograms6secnew/bhojpuri_pop/Ankush Raja - Dar kekra se ba14.png\"\n",
    "\n",
    "filenameparts=file_name.split('/')\n",
    "song_name=filenameparts[-1]\n",
    "song_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram(block,sr,genre,song_name,counter):\n",
    "  matplotlib.use('Agg')\n",
    "  S = librosa.feature.melspectrogram(y=block, sr=sr, n_mels=128,fmax=8000)\n",
    "  plt.figure(figsize=(6, 3))\n",
    "  librosa.display.specshow(librosa.power_to_db(S,ref=np.max),y_axis='mel', fmax=8000,x_axis='time')\n",
    "  # plt.plot()\n",
    "  song_name=song_name.replace('.mp3','')\n",
    "  file_name=f'testset/{genre}/'+song_name+str(counter)+'.png'\n",
    "  plt.savefig(file_name)\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayushmaankaushik/.local/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:164\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    167\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:195\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[1;32m    197\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/soundfile.py:655\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    654\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    656\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    657\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/soundfile.py:1213\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1213\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m   1214\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1215\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '../content/spectrograms6secnew/bhojpuri_pop/Ankush Raja - Dar kekra se ba14.png': Format not recognised.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(file_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:170\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    169\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 170\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:226\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    223\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[1;32m    228\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    229\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/audioread/__init__.py:132\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m# All backends failed!\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m \u001b[39mraise\u001b[39;00m NoBackendError()\n",
      "\u001b[0;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "audio, sr = librosa.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Audio(data\u001b[39m=\u001b[39maudio, rate\u001b[39m=\u001b[39msr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'audio' is not defined"
     ]
    }
   ],
   "source": [
    "Audio(data=audio, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'loadsong'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mloadsong\u001b[39;00m\n\u001b[1;32m      3\u001b[0m loadsong\u001b[39m.\u001b[39mmake_spectrograms(audio,sr,song_name)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'loadsong'"
     ]
    }
   ],
   "source": [
    "import loadsong\n",
    "\n",
    "loadsong.make_spectrograms(audio,sr,song_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('testset')\n",
    "dest_path='testset'\n",
    "\n",
    "for genre in genre_list:\n",
    "  os.mkdir(f'testset/{genre}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_test=\"../content/spectrograms6secnew/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../content/spectrograms6secnew')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_path='../content/spectrograms6secnew'\n",
    "\n",
    "data_dir=pathlib.Path(dest_path)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29990 files belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 19:30:35.752392: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-17 19:30:35.752425: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-17 19:30:35.752443: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n",
      "2022-11-17 19:30:35.753434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29990 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#defining dataset dimensions\n",
    "batch_size=64\n",
    "image_height=100\n",
    "image_width=200\n",
    "\n",
    "#loading datasets\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_test,\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size,\n",
    "  shuffle=\"False\"\n",
    "  )\n",
    "\n",
    "test_ds_cnn = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_test,\n",
    "  seed=123,\n",
    "  image_size=(75, 150),\n",
    "  batch_size=batch_size,\n",
    "  shuffle=\"False\"\n",
    "  )\n",
    "\n",
    "genre_list=test_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "load_model=tensorflow.keras.models.load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_models(model_genres:list,model_input,model_input_cnn):\n",
    "    #loading all models\n",
    "    models=[]\n",
    "    models.append(load_model('../FinalModel/models/model1/'))\n",
    "    models.append(load_model('../FinalModel/models/model2/'))\n",
    "    models.append(load_model('../FinalModel/models/model3/'))\n",
    "    models.append(load_model('../FinalModel/models/model4/'))\n",
    "\n",
    "    #prediction\n",
    "    model1=models[0].predict(model_input)\n",
    "    model2=models[1].predict(model_input)\n",
    "    model3=models[2].predict(model_input)\n",
    "    model4=models[3].predict(model_input_cnn)\n",
    "\n",
    "    avgEnsemble=(model1+model2+model3+model4)/len(models)\n",
    "\n",
    "    avgLis=[]\n",
    "    for i in avgEnsemble:\n",
    "        avgLis.append(i.argmax())\n",
    "    \n",
    "    most_confi=max(avgLis,key=avgLis.count)\n",
    "\n",
    "    return model_genres[most_confi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../content/spectrograms6secnew/bhojpuri_pop/Ankush Raja - Dar kekra se ba14.png Ankush Raja - Dar kekra se ba14.png\n",
      "469/469 [==============================] - 75s 158ms/step\n",
      "469/469 [==============================] - 76s 160ms/step\n",
      "118/469 [======>.......................] - ETA: 1:12"
     ]
    }
   ],
   "source": [
    "best_genre = ensemble_models(genre_list,test_ds,test_ds_cnn)\n",
    "print(best_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9856211725461667\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from scipy import spatial\n",
    "\n",
    "test_image1 = Image.open(\"../content/spectrograms6secnew/ghazal/Abida Parveen - Niyaten-e-Shauq Bhar Na20.png\")\n",
    "test_image2 = Image.open(\"../content/spectrograms6secnew/desi_pop/A.R. Rahman, Arijit Singh - Enna Sona18.png\")\n",
    "\n",
    "img_1 = test_image1.resize((100,200))\n",
    "img_2 = test_image2.resize((100,200))\n",
    "\n",
    "arr_1 = np.array(img_1)\n",
    "arr_2 = np.array(img_2)\n",
    "\n",
    "arr_1 = arr_1.flatten()\n",
    "arr_2 = arr_2.flatten()\n",
    "\n",
    "arr_1 = arr_1/255\n",
    "arr_2 = arr_2/255\n",
    "\n",
    "similarity = -1 * (spatial.distance.cosine(arr_1,arr_2) - 1)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_array(image):\n",
    "    img = image.resize((100,200))\n",
    "    img_arr = np.array(img)\n",
    "    img_arr = img_arr.flatten()\n",
    "    img_arr = img_arr/255\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_name(img_name):\n",
    "    return ''.join((x for x in img_name[:-4] if not x.isdigit()))\n",
    "\n",
    "compared_image = get_image_array(test_image1)\n",
    "similarity_images = []\n",
    "path = os.path.join(dest_path,best_genre)\n",
    "prev_song_name = ''\n",
    "for images in os.listdir(path):\n",
    "    image_obj = Image.open(os.path.join(path,images))\n",
    "    \n",
    "    image2 = get_image_array(image_obj)\n",
    "    similarity = -1 * (spatial.distance.cosine(compared_image,image2) - 1)\n",
    "    image_name = images.split('\\\\')[-1]\n",
    "    song_name = get_song_name(image_name)\n",
    "    \n",
    "    prev_song_name = song_name\n",
    "    similarity_images.append([song_name,similarity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abida Parveen - Niyaten-e-Shauq Bhar Na</td>\n",
       "      <td>0.987568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Talat Aziz - Ab Kya Ghazal Sunaoon</td>\n",
       "      <td>0.987326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Jagjit Singh - Koi Yeh Kaise Bataye</td>\n",
       "      <td>0.987156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Ravi Bal - Ishqe Noo Ched Na Bethi</td>\n",
       "      <td>0.987091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Nafad Sinan - Dastoor</td>\n",
       "      <td>0.987018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Joell, Chinmayi Tripathi, Shriram Sampath - Da...</td>\n",
       "      <td>0.986811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Jagjit Singh - Shayad Main Zindagi Ki Sahar</td>\n",
       "      <td>0.986805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bayaan - Farda</td>\n",
       "      <td>0.986783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ghulam Ali - Roya</td>\n",
       "      <td>0.986781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Mehdi Hassan - Duniya Kisi Ke</td>\n",
       "      <td>0.986681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name     Score\n",
       "0             Abida Parveen - Niyaten-e-Shauq Bhar Na  0.987568\n",
       "94                 Talat Aziz - Ab Kya Ghazal Sunaoon  0.987326\n",
       "44                Jagjit Singh - Koi Yeh Kaise Bataye  0.987156\n",
       "88                 Ravi Bal - Ishqe Noo Ched Na Bethi  0.987091\n",
       "75                              Nafad Sinan - Dastoor  0.987018\n",
       "53  Joell, Chinmayi Tripathi, Shriram Sampath - Da...  0.986811\n",
       "46        Jagjit Singh - Shayad Main Zindagi Ki Sahar  0.986805\n",
       "11                                     Bayaan - Farda  0.986783\n",
       "32                                  Ghulam Ali - Roya  0.986781\n",
       "64                      Mehdi Hassan - Duniya Kisi Ke  0.986681"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(similarity_images,columns=[\"Name\",\"Score\"])\n",
    "avgeraged_similarities = df.groupby('Name').mean('Score').reset_index()\n",
    "suggestions = avgeraged_similarities.sort_values('Score',ascending=False).head(10)\n",
    "# suggestions = df.sort_values('Score',ascending=False).head(10)\n",
    "suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
