{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS put all here\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#tf imports for reading file\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#extras\n",
    "print(tf.__version__)\n",
    "import pathlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to image dataset\n",
    "spec_path = 'content/spectrograms6sec'\n",
    "\n",
    "genre_list=os.listdir(spec_path)\n",
    "genre_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resets the experiment\n",
    "#%rm -rf content/spectrograms6secnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('content/spectrograms6secnew')\n",
    "# dest_path='content/spectrograms6secnew'\n",
    "\n",
    "# for genre in genre_list:\n",
    "#   os.mkdir(f'content/spectrograms6secnew/{genre}')\n",
    "\n",
    "\n",
    "\n",
    "# #no of samples per class\n",
    "# n=3000\n",
    "# cnt=0\n",
    "\n",
    "# random.seed(123)\n",
    "\n",
    "# for genre in genre_list:\n",
    "#   genre_path=os.path.join(spec_path,genre)\n",
    "#   dest_genre_path=os.path.join(dest_path,genre)\n",
    "\n",
    "#   #shuffling and selecting 3000 samples\n",
    "#   genre_songs=os.listdir(genre_path)\n",
    "#   random.shuffle(genre_songs)\n",
    "#   selected_spec=genre_songs[:n]\n",
    "  \n",
    "#   for song in selected_spec:\n",
    "#       source=os.path.join(genre_path,song)\n",
    "#       dest=os.path.join(dest_genre_path,song)\n",
    "#       d= shutil.copyfile(source, dest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path='content/spectrograms6secnew'\n",
    "data_dir=pathlib.Path(dest_path)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding dataset\n",
    "batch_size=64\n",
    "image_height=100\n",
    "image_width=200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(45, 15))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING LEARNING RATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logs/scalars/20221107-221910/validation -0.3\n",
    "logs/scalars/20221107-231918/validation -0.1\n",
    "logs/scalars/20221108-001905/validation -0.03\n",
    "logs/scalars/20221108-011800/validation -0.01\n",
    "logs/scalars/20221108-021755/validation -0.003\n",
    "logs/scalars/20221108-031741/validation -0.001\n",
    "logs/scalars/20221108-041732/validation -0.0003\n",
    "logs/scalars/20221108-051723/validation -0.0001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.3)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "```\n",
    "```\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " rescaling_1 (Rescaling)     (None, 100, 200, 3)       0         \n",
    "                                                                 \n",
    " conv2d (Conv2D)             (None, 100, 200, 32)      896       \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 100, 200, 16)      4624      \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 50, 100, 16)      0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_2 (Conv2D)           (None, 50, 100, 8)        2056      \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 25, 50, 8)        0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 10000)             0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               1280128   \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 10)                1290      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,288,994\n",
    "Trainable params: 1,288,994\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "375/375 [==============================] - 381s 1s/step - loss: 58.4071 - accuracy: 0.0990 - val_loss: 12.3220 - val_accuracy: 0.0982\n",
    "Epoch 2/10\n",
    "375/375 [==============================] - 360s 960ms/step - loss: 7.6695 - accuracy: 0.0986 - val_loss: 5.1379 - val_accuracy: 0.0982\n",
    "Epoch 3/10\n",
    "375/375 [==============================] - 359s 958ms/step - loss: 4.0421 - accuracy: 0.0986 - val_loss: 3.2170 - val_accuracy: 0.0982\n",
    "Epoch 4/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 2.8428 - accuracy: 0.0986 - val_loss: 2.5564 - val_accuracy: 0.0982\n",
    "Epoch 5/10\n",
    "375/375 [==============================] - 358s 953ms/step - loss: 2.4569 - accuracy: 0.0989 - val_loss: 2.3626 - val_accuracy: 0.0982\n",
    "Epoch 6/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 2.3537 - accuracy: 0.0989 - val_loss: 2.3194 - val_accuracy: 0.0982\n",
    "Epoch 7/10\n",
    "375/375 [==============================] - 357s 952ms/step - loss: 2.3363 - accuracy: 0.0989 - val_loss: 2.3140 - val_accuracy: 0.0982\n",
    "Epoch 8/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 2.3314 - accuracy: 0.0989 - val_loss: 2.3160 - val_accuracy: 0.0982\n",
    "Epoch 9/10\n",
    "375/375 [==============================] - 358s 954ms/step - loss: 2.3328 - accuracy: 0.0989 - val_loss: 2.3149 - val_accuracy: 0.0982\n",
    "Epoch 10/10\n",
    "375/375 [==============================] - 359s 958ms/step - loss: 2.3310 - accuracy: 0.0989 - val_loss: 2.3126 - val_accuracy: 0.0982\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "```\n",
    "```\n",
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " rescaling_2 (Rescaling)     (None, 100, 200, 3)       0         \n",
    "                                                                 \n",
    " conv2d_3 (Conv2D)           (None, 100, 200, 32)      896       \n",
    "                                                                 \n",
    " conv2d_4 (Conv2D)           (None, 100, 200, 16)      4624      \n",
    "                                                                 \n",
    " max_pooling2d_2 (MaxPooling  (None, 50, 100, 16)      0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " conv2d_5 (Conv2D)           (None, 50, 100, 8)        2056      \n",
    "                                                                 \n",
    " max_pooling2d_3 (MaxPooling  (None, 25, 50, 8)        0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten_1 (Flatten)         (None, 10000)             0         \n",
    "                                                                 \n",
    " dense_2 (Dense)             (None, 128)               1280128   \n",
    "                                                                 \n",
    " dense_3 (Dense)             (None, 10)                1290      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,288,994\n",
    "Trainable params: 1,288,994\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "375/375 [==============================] - 360s 958ms/step - loss: 29.8500 - accuracy: 0.0995 - val_loss: 9.7327 - val_accuracy: 0.1022\n",
    "Epoch 2/10\n",
    "375/375 [==============================] - 358s 955ms/step - loss: 8.0908 - accuracy: 0.0985 - val_loss: 6.5925 - val_accuracy: 0.1022\n",
    "Epoch 3/10\n",
    "375/375 [==============================] - 360s 960ms/step - loss: 5.4973 - accuracy: 0.0977 - val_loss: 4.5701 - val_accuracy: 0.1022\n",
    "Epoch 4/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 3.9830 - accuracy: 0.0982 - val_loss: 3.5058 - val_accuracy: 0.1022\n",
    "Epoch 5/10\n",
    "375/375 [==============================] - 359s 956ms/step - loss: 3.2334 - accuracy: 0.0986 - val_loss: 3.0100 - val_accuracy: 0.1022\n",
    "Epoch 6/10\n",
    "375/375 [==============================] - 358s 954ms/step - loss: 2.8887 - accuracy: 0.0988 - val_loss: 2.7788 - val_accuracy: 0.1022\n",
    "Epoch 7/10\n",
    "375/375 [==============================] - 359s 956ms/step - loss: 2.7168 - accuracy: 0.0988 - val_loss: 2.6492 - val_accuracy: 0.1022\n",
    "Epoch 8/10\n",
    "375/375 [==============================] - 358s 953ms/step - loss: 2.6086 - accuracy: 0.0988 - val_loss: 2.5567 - val_accuracy: 0.1022\n",
    "Epoch 9/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 2.5254 - accuracy: 0.0988 - val_loss: 2.4817 - val_accuracy: 0.1022\n",
    "Epoch 10/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 2.4577 - accuracy: 0.0988 - val_loss: 2.4212 - val_accuracy: 0.1022\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.03)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "```\n",
    "```\n",
    "Model: \"sequential_2\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " rescaling_3 (Rescaling)     (None, 100, 200, 3)       0         \n",
    "                                                                 \n",
    " conv2d_6 (Conv2D)           (None, 100, 200, 32)      896       \n",
    "                                                                 \n",
    " conv2d_7 (Conv2D)           (None, 100, 200, 16)      4624      \n",
    "                                                                 \n",
    " max_pooling2d_4 (MaxPooling  (None, 50, 100, 16)      0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " conv2d_8 (Conv2D)           (None, 50, 100, 8)        2056      \n",
    "                                                                 \n",
    " max_pooling2d_5 (MaxPooling  (None, 25, 50, 8)        0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten_2 (Flatten)         (None, 10000)             0         \n",
    "                                                                 \n",
    " dense_4 (Dense)             (None, 128)               1280128   \n",
    "                                                                 \n",
    " dense_5 (Dense)             (None, 10)                1290      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,288,994\n",
    "Trainable params: 1,288,994\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "375/375 [==============================] - 354s 943ms/step - loss: 2.4425 - accuracy: 0.0964 - val_loss: 2.3057 - val_accuracy: 0.1037\n",
    "Epoch 2/10\n",
    "375/375 [==============================] - 355s 948ms/step - loss: 2.3064 - accuracy: 0.0953 - val_loss: 2.3049 - val_accuracy: 0.1037\n",
    "Epoch 3/10\n",
    "375/375 [==============================] - 351s 936ms/step - loss: 2.3061 - accuracy: 0.0946 - val_loss: 2.3048 - val_accuracy: 0.1037\n",
    "Epoch 4/10\n",
    "375/375 [==============================] - 355s 945ms/step - loss: 2.3059 - accuracy: 0.0957 - val_loss: 2.3046 - val_accuracy: 0.1037\n",
    "Epoch 5/10\n",
    "375/375 [==============================] - 353s 940ms/step - loss: 2.3058 - accuracy: 0.0967 - val_loss: 2.3044 - val_accuracy: 0.1037\n",
    "Epoch 6/10\n",
    "375/375 [==============================] - 355s 946ms/step - loss: 2.3057 - accuracy: 0.0961 - val_loss: 2.3044 - val_accuracy: 0.1037\n",
    "Epoch 7/10\n",
    "375/375 [==============================] - 352s 939ms/step - loss: 2.3057 - accuracy: 0.0962 - val_loss: 2.3044 - val_accuracy: 0.1037\n",
    "Epoch 8/10\n",
    "375/375 [==============================] - 354s 944ms/step - loss: 2.3057 - accuracy: 0.0962 - val_loss: 2.3044 - val_accuracy: 0.1037\n",
    "Epoch 9/10\n",
    "375/375 [==============================] - 353s 941ms/step - loss: 2.3057 - accuracy: 0.0962 - val_loss: 2.3044 - val_accuracy: 0.1037\n",
    "Epoch 10/10\n",
    "375/375 [==============================] - 354s 943ms/step - loss: 2.3057 - accuracy: 0.0962 - val_loss: 2.3044 - val_accuracy: 0.1037\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "```\n",
    "```\n",
    "Model: \"sequential_3\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " rescaling_4 (Rescaling)     (None, 100, 200, 3)       0         \n",
    "                                                                 \n",
    " conv2d_9 (Conv2D)           (None, 100, 200, 32)      896       \n",
    "                                                                 \n",
    " conv2d_10 (Conv2D)          (None, 100, 200, 16)      4624      \n",
    "                                                                 \n",
    " max_pooling2d_6 (MaxPooling  (None, 50, 100, 16)      0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " conv2d_11 (Conv2D)          (None, 50, 100, 8)        2056      \n",
    "                                                                 \n",
    " max_pooling2d_7 (MaxPooling  (None, 25, 50, 8)        0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten_3 (Flatten)         (None, 10000)             0         \n",
    "                                                                 \n",
    " dense_6 (Dense)             (None, 128)               1280128   \n",
    "                                                                 \n",
    " dense_7 (Dense)             (None, 10)                1290      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,288,994\n",
    "Trainable params: 1,288,994\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "375/375 [==============================] - 356s 950ms/step - loss: 2.3977 - accuracy: 0.0984 - val_loss: 2.3038 - val_accuracy: 0.0980\n",
    "Epoch 2/10\n",
    "375/375 [==============================] - 354s 944ms/step - loss: 2.3039 - accuracy: 0.0986 - val_loss: 2.3034 - val_accuracy: 0.0980\n",
    "Epoch 3/10\n",
    "375/375 [==============================] - 361s 964ms/step - loss: 2.3038 - accuracy: 0.0991 - val_loss: 2.3034 - val_accuracy: 0.0980\n",
    "Epoch 4/10\n",
    "375/375 [==============================] - 360s 960ms/step - loss: 2.3038 - accuracy: 0.0992 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
    "Epoch 5/10\n",
    "375/375 [==============================] - 364s 970ms/step - loss: 2.3038 - accuracy: 0.0989 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
    "Epoch 6/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 2.3038 - accuracy: 0.0990 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
    "Epoch 7/10\n",
    "375/375 [==============================] - 362s 964ms/step - loss: 2.3038 - accuracy: 0.0993 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
    "Epoch 8/10\n",
    "375/375 [==============================] - 360s 959ms/step - loss: 2.3038 - accuracy: 0.0990 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
    "Epoch 9/10\n",
    "375/375 [==============================] - 359s 958ms/step - loss: 2.3038 - accuracy: 0.0992 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
    "Epoch 10/10\n",
    "375/375 [==============================] - 360s 960ms/step - loss: 2.3038 - accuracy: 0.0989 - val_loss: 2.3033 - val_accuracy: 0.0980\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "```\n",
    "```\n",
    "Model: \"sequential_4\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " rescaling_5 (Rescaling)     (None, 100, 200, 3)       0         \n",
    "                                                                 \n",
    " conv2d_12 (Conv2D)          (None, 100, 200, 32)      896       \n",
    "                                                                 \n",
    " conv2d_13 (Conv2D)          (None, 100, 200, 16)      4624      \n",
    "                                                                 \n",
    " max_pooling2d_8 (MaxPooling  (None, 50, 100, 16)      0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " conv2d_14 (Conv2D)          (None, 50, 100, 8)        2056      \n",
    "                                                                 \n",
    " max_pooling2d_9 (MaxPooling  (None, 25, 50, 8)        0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten_4 (Flatten)         (None, 10000)             0         \n",
    "                                                                 \n",
    " dense_8 (Dense)             (None, 128)               1280128   \n",
    "                                                                 \n",
    " dense_9 (Dense)             (None, 10)                1290      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,288,994\n",
    "Trainable params: 1,288,994\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "375/375 [==============================] - 360s 959ms/step - loss: 2.1252 - accuracy: 0.2685 - val_loss: 1.7957 - val_accuracy: 0.3875\n",
    "Epoch 2/10\n",
    "375/375 [==============================] - 360s 959ms/step - loss: 1.6317 - accuracy: 0.4310 - val_loss: 1.5269 - val_accuracy: 0.4760\n",
    "Epoch 3/10\n",
    "375/375 [==============================] - 359s 958ms/step - loss: 1.5035 - accuracy: 0.4798 - val_loss: 1.5015 - val_accuracy: 0.4850\n",
    "Epoch 4/10\n",
    "375/375 [==============================] - 358s 955ms/step - loss: 1.5576 - accuracy: 0.4659 - val_loss: 1.4656 - val_accuracy: 0.4910\n",
    "Epoch 5/10\n",
    "375/375 [==============================] - 358s 954ms/step - loss: 1.3678 - accuracy: 0.5357 - val_loss: 1.4228 - val_accuracy: 0.5130\n",
    "Epoch 6/10\n",
    "375/375 [==============================] - 361s 962ms/step - loss: 1.2600 - accuracy: 0.5745 - val_loss: 1.4866 - val_accuracy: 0.5018\n",
    "Epoch 7/10\n",
    "375/375 [==============================] - 358s 954ms/step - loss: 1.1662 - accuracy: 0.6093 - val_loss: 1.5191 - val_accuracy: 0.5035\n",
    "Epoch 8/10\n",
    "375/375 [==============================] - 358s 955ms/step - loss: 1.0831 - accuracy: 0.6395 - val_loss: 1.5529 - val_accuracy: 0.5113\n",
    "Epoch 9/10\n",
    "375/375 [==============================] - 357s 951ms/step - loss: 1.0005 - accuracy: 0.6688 - val_loss: 1.5741 - val_accuracy: 0.5168\n",
    "Epoch 10/10\n",
    "375/375 [==============================] - 359s 956ms/step - loss: 0.9443 - accuracy: 0.6915 - val_loss: 1.6907 - val_accuracy: 0.5100\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "```\n",
    "\n",
    "```\n",
    "Model: \"sequential_5\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " rescaling_6 (Rescaling)     (None, 100, 200, 3)       0         \n",
    "                                                                 \n",
    " conv2d_15 (Conv2D)          (None, 100, 200, 32)      896       \n",
    "                                                                 \n",
    " conv2d_16 (Conv2D)          (None, 100, 200, 16)      4624      \n",
    "                                                                 \n",
    " max_pooling2d_10 (MaxPoolin  (None, 50, 100, 16)      0         \n",
    " g2D)                                                            \n",
    "                                                                 \n",
    " conv2d_17 (Conv2D)          (None, 50, 100, 8)        2056      \n",
    "                                                                 \n",
    " max_pooling2d_11 (MaxPoolin  (None, 25, 50, 8)        0         \n",
    " g2D)                                                            \n",
    "                                                                 \n",
    " flatten_5 (Flatten)         (None, 10000)             0         \n",
    "                                                                 \n",
    " dense_10 (Dense)            (None, 128)               1280128   \n",
    "                                                                 \n",
    " dense_11 (Dense)            (None, 10)                1290      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,288,994\n",
    "Trainable params: 1,288,994\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "375/375 [==============================] - 360s 959ms/step - loss: 2.2036 - accuracy: 0.3553 - val_loss: 1.5372 - val_accuracy: 0.4793\n",
    "Epoch 2/10\n",
    "375/375 [==============================] - 361s 962ms/step - loss: 1.4216 - accuracy: 0.5250 - val_loss: 1.3399 - val_accuracy: 0.5493\n",
    "Epoch 3/10\n",
    "375/375 [==============================] - 357s 952ms/step - loss: 1.2238 - accuracy: 0.5894 - val_loss: 1.2159 - val_accuracy: 0.5923\n",
    "Epoch 4/10\n",
    "375/375 [==============================] - 360s 960ms/step - loss: 1.0849 - accuracy: 0.6390 - val_loss: 1.1919 - val_accuracy: 0.6010\n",
    "Epoch 5/10\n",
    "375/375 [==============================] - 359s 956ms/step - loss: 0.9770 - accuracy: 0.6769 - val_loss: 1.1524 - val_accuracy: 0.6137\n",
    "Epoch 6/10\n",
    "375/375 [==============================] - 360s 959ms/step - loss: 0.8837 - accuracy: 0.7119 - val_loss: 1.1650 - val_accuracy: 0.6130\n",
    "Epoch 7/10\n",
    "375/375 [==============================] - 357s 953ms/step - loss: 0.7955 - accuracy: 0.7458 - val_loss: 1.2113 - val_accuracy: 0.6073\n",
    "Epoch 8/10\n",
    "375/375 [==============================] - 358s 956ms/step - loss: 0.7120 - accuracy: 0.7733 - val_loss: 1.2687 - val_accuracy: 0.5982\n",
    "Epoch 9/10\n",
    "375/375 [==============================] - 359s 959ms/step - loss: 0.6490 - accuracy: 0.7945 - val_loss: 1.3395 - val_accuracy: 0.5990\n",
    "Epoch 10/10\n",
    "375/375 [==============================] - 359s 958ms/step - loss: 0.6092 - accuracy: 0.8043 - val_loss: 1.3789 - val_accuracy: 0.5992\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "```\n",
    "```\n",
    "Model: \"sequential_6\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " rescaling_7 (Rescaling)     (None, 100, 200, 3)       0         \n",
    "                                                                 \n",
    " conv2d_18 (Conv2D)          (None, 100, 200, 32)      896       \n",
    "                                                                 \n",
    " conv2d_19 (Conv2D)          (None, 100, 200, 16)      4624      \n",
    "                                                                 \n",
    " max_pooling2d_12 (MaxPoolin  (None, 50, 100, 16)      0         \n",
    " g2D)                                                            \n",
    "                                                                 \n",
    " conv2d_20 (Conv2D)          (None, 50, 100, 8)        2056      \n",
    "                                                                 \n",
    " max_pooling2d_13 (MaxPoolin  (None, 25, 50, 8)        0         \n",
    " g2D)                                                            \n",
    "                                                                 \n",
    " flatten_6 (Flatten)         (None, 10000)             0         \n",
    "                                                                 \n",
    " dense_12 (Dense)            (None, 128)               1280128   \n",
    "                                                                 \n",
    " dense_13 (Dense)            (None, 10)                1290      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,288,994\n",
    "Trainable params: 1,288,994\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "375/375 [==============================] - 359s 956ms/step - loss: 2.9556 - accuracy: 0.3053 - val_loss: 2.1315 - val_accuracy: 0.4298\n",
    "Epoch 2/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 1.8066 - accuracy: 0.4777 - val_loss: 1.5961 - val_accuracy: 0.5232\n",
    "Epoch 3/10\n",
    "375/375 [==============================] - 359s 958ms/step - loss: 1.4929 - accuracy: 0.5420 - val_loss: 1.4192 - val_accuracy: 0.5663\n",
    "Epoch 4/10\n",
    "375/375 [==============================] - 358s 956ms/step - loss: 1.3604 - accuracy: 0.5783 - val_loss: 1.3356 - val_accuracy: 0.5855\n",
    "Epoch 5/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 1.2702 - accuracy: 0.6041 - val_loss: 1.2847 - val_accuracy: 0.5983\n",
    "Epoch 6/10\n",
    "375/375 [==============================] - 360s 960ms/step - loss: 1.1908 - accuracy: 0.6274 - val_loss: 1.2618 - val_accuracy: 0.6037\n",
    "Epoch 7/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 1.1246 - accuracy: 0.6479 - val_loss: 1.2373 - val_accuracy: 0.6045\n",
    "Epoch 8/10\n",
    "375/375 [==============================] - 359s 958ms/step - loss: 1.0668 - accuracy: 0.6651 - val_loss: 1.2233 - val_accuracy: 0.6088\n",
    "Epoch 9/10\n",
    "375/375 [==============================] - 359s 958ms/step - loss: 1.0108 - accuracy: 0.6845 - val_loss: 1.2099 - val_accuracy: 0.6145\n",
    "Epoch 10/10\n",
    "375/375 [==============================] - 359s 957ms/step - loss: 0.9582 - accuracy: 0.6993 - val_loss: 1.1972 - val_accuracy: 0.6223\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=10\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "```\n",
    "```\n",
    "Model: \"sequential_7\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " rescaling_8 (Rescaling)     (None, 100, 200, 3)       0         \n",
    "                                                                 \n",
    " conv2d_21 (Conv2D)          (None, 100, 200, 32)      896       \n",
    "                                                                 \n",
    " conv2d_22 (Conv2D)          (None, 100, 200, 16)      4624      \n",
    "                                                                 \n",
    " max_pooling2d_14 (MaxPoolin  (None, 50, 100, 16)      0         \n",
    " g2D)                                                            \n",
    "                                                                 \n",
    " conv2d_23 (Conv2D)          (None, 50, 100, 8)        2056      \n",
    "                                                                 \n",
    " max_pooling2d_15 (MaxPoolin  (None, 25, 50, 8)        0         \n",
    " g2D)                                                            \n",
    "                                                                 \n",
    " flatten_7 (Flatten)         (None, 10000)             0         \n",
    "                                                                 \n",
    " dense_14 (Dense)            (None, 128)               1280128   \n",
    "                                                                 \n",
    " dense_15 (Dense)            (None, 10)                1290      \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 1,288,994\n",
    "Trainable params: 1,288,994\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "375/375 [==============================] - 361s 961ms/step - loss: 3.3621 - accuracy: 0.3098 - val_loss: 2.7675 - val_accuracy: 0.4415\n",
    "Epoch 2/10\n",
    "375/375 [==============================] - 360s 960ms/step - loss: 2.4738 - accuracy: 0.4602 - val_loss: 2.2283 - val_accuracy: 0.4955\n",
    "Epoch 3/10\n",
    "375/375 [==============================] - 359s 956ms/step - loss: 2.0568 - accuracy: 0.5067 - val_loss: 1.9171 - val_accuracy: 0.5253\n",
    "Epoch 4/10\n",
    "375/375 [==============================] - 361s 963ms/step - loss: 1.8008 - accuracy: 0.5377 - val_loss: 1.7214 - val_accuracy: 0.5478\n",
    "Epoch 5/10\n",
    "375/375 [==============================] - 358s 956ms/step - loss: 1.6304 - accuracy: 0.5585 - val_loss: 1.5972 - val_accuracy: 0.5578\n",
    "Epoch 6/10\n",
    "375/375 [==============================] - 361s 962ms/step - loss: 1.5106 - accuracy: 0.5782 - val_loss: 1.4987 - val_accuracy: 0.5682\n",
    "Epoch 7/10\n",
    "375/375 [==============================] - 362s 966ms/step - loss: 1.4228 - accuracy: 0.5942 - val_loss: 1.4522 - val_accuracy: 0.5767\n",
    "Epoch 8/10\n",
    "375/375 [==============================] - 363s 967ms/step - loss: 1.3558 - accuracy: 0.6078 - val_loss: 1.3846 - val_accuracy: 0.5910\n",
    "Epoch 9/10\n",
    "375/375 [==============================] - 366s 975ms/step - loss: 1.3001 - accuracy: 0.6202 - val_loss: 1.3533 - val_accuracy: 0.5963\n",
    "Epoch 10/10\n",
    "375/375 [==============================] - 363s 969ms/step - loss: 1.2515 - accuracy: 0.6330 - val_loss: 1.3151 - val_accuracy: 0.6035\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ai_ml_nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75f149aabefc45f596bad3ecd1cce999665dc47c609d2b6ed1c0c06088326543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
