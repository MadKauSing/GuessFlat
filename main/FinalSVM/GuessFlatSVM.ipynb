{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 08:19:09.696842: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-15 08:19:09.696868: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/ayushsingh/anaconda3/envs/ai_ml_nn/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS put all here\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#tf imports for reading file\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "#extras\n",
    "print(tf.__version__)\n",
    "import pathlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to image dataset\n",
    "spec_path = '../content/spectrograms6sec'\n",
    "chroma_path='../content/chroma6sec'\n",
    "test_path='../content/testset'\n",
    "genre_list=os.listdir(spec_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('../content/chroma6secnew')\n",
    "# dest_path='../content/chroma6secnew'\n",
    "\n",
    "# for genre in genre_list:\n",
    "#   os.mkdir(f'../content/chroma6secnew/{genre}')\n",
    "\n",
    "\n",
    "\n",
    "# #no of samples per class\n",
    "# n=3000\n",
    "# cnt=0\n",
    "\n",
    "# random.seed(123)\n",
    "\n",
    "# for genre in genre_list:\n",
    "#   genre_path=os.path.join(chroma_path,genre)\n",
    "#   dest_genre_path=os.path.join(dest_path,genre)\n",
    "\n",
    "#   #shuffling and selecting 3000 samples\n",
    "#   genre_songs=os.listdir(genre_path)\n",
    "#   random.shuffle(genre_songs)\n",
    "#   selected_spec=genre_songs[:n]\n",
    "  \n",
    "#   for song in selected_spec:\n",
    "#       source=os.path.join(genre_path,song)\n",
    "#       dest=os.path.join(dest_genre_path,song)\n",
    "#       d= shutil.copyfile(source, dest)\n",
    "\n",
    "\n",
    "# EQUALISING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data_sets\n",
    "spec_path='../content/spectrograms6secnew/'\n",
    "chroma_path='../content/chroma6secnew/'\n",
    "\n",
    "data_dir_spec=pathlib.Path(spec_path)\n",
    "data_dir_chroma=pathlib.Path(chroma_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding dataset\n",
    "batch_size=64\n",
    "image_height=100\n",
    "image_width=200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 10 classes.\n",
      "Using 24000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 08:19:16.305613: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-15 08:19:16.305638: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-15 08:19:16.305655: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (CoderCatA5Pop): /proc/driver/nvidia/version does not exist\n",
      "2022-11-15 08:19:16.305884: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 10 classes.\n",
      "Using 24000 files for training.\n"
     ]
    }
   ],
   "source": [
    "#training dataset spectrograms\n",
    "train_ds_spec = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_spec,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "# training dataset chromagrams\n",
    "\n",
    "train_ds_chroma = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_chroma,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 files belonging to 10 classes.\n",
      "Using 6000 files for validation.\n",
      "Found 30000 files belonging to 10 classes.\n",
      "Using 6000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds_spec = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_spec,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds_chroma = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_chroma,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 200, 3)\n",
      "(64,)\n",
      "(64, 100, 200, 3)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds_spec:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n",
    "for image_batch, labels_batch in train_ds_chroma:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds_spec.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#\n",
    "train_ds_spec = train_ds_spec.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds_spec = val_ds_spec.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "#\n",
    "train_ds_chroma = train_ds_chroma.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds_chroma = val_ds_chroma.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING SPECTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 100, 200, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 100, 200, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 50, 100, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 100, 16)       2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 50, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 50, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 25, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1228928   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237,626\n",
      "Trainable params: 1,237,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 105s 277ms/step - loss: 2.8599 - accuracy: 0.3210 - val_loss: 2.0960 - val_accuracy: 0.4205\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 90s 240ms/step - loss: 1.8543 - accuracy: 0.4488 - val_loss: 1.6490 - val_accuracy: 0.4963\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 1.5777 - accuracy: 0.5044 - val_loss: 1.4767 - val_accuracy: 0.5368\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 1.4460 - accuracy: 0.5380 - val_loss: 1.3814 - val_accuracy: 0.5645\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 89s 237ms/step - loss: 1.3574 - accuracy: 0.5650 - val_loss: 1.3158 - val_accuracy: 0.5808\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 89s 239ms/step - loss: 1.2894 - accuracy: 0.5858 - val_loss: 1.2662 - val_accuracy: 0.5920\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 89s 239ms/step - loss: 1.2312 - accuracy: 0.6023 - val_loss: 1.2285 - val_accuracy: 0.6040\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 1.1814 - accuracy: 0.6192 - val_loss: 1.1977 - val_accuracy: 0.6092\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 88s 236ms/step - loss: 1.1356 - accuracy: 0.6335 - val_loss: 1.1724 - val_accuracy: 0.6145\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 89s 236ms/step - loss: 1.0942 - accuracy: 0.6478 - val_loss: 1.1520 - val_accuracy: 0.6242\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 89s 237ms/step - loss: 1.0560 - accuracy: 0.6605 - val_loss: 1.1345 - val_accuracy: 0.6270\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 1.0195 - accuracy: 0.6733 - val_loss: 1.1168 - val_accuracy: 0.6330\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 0.9843 - accuracy: 0.6863 - val_loss: 1.1027 - val_accuracy: 0.6403\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 89s 236ms/step - loss: 0.9504 - accuracy: 0.6974 - val_loss: 1.0905 - val_accuracy: 0.6438\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 0.9166 - accuracy: 0.7084 - val_loss: 1.0821 - val_accuracy: 0.6463\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 89s 237ms/step - loss: 0.8840 - accuracy: 0.7199 - val_loss: 1.0783 - val_accuracy: 0.6488\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 90s 239ms/step - loss: 0.8524 - accuracy: 0.7312 - val_loss: 1.0722 - val_accuracy: 0.6528\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 90s 239ms/step - loss: 0.8217 - accuracy: 0.7428 - val_loss: 1.0715 - val_accuracy: 0.6560\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 89s 237ms/step - loss: 0.7914 - accuracy: 0.7537 - val_loss: 1.0689 - val_accuracy: 0.6577\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 0.7614 - accuracy: 0.7642 - val_loss: 1.0651 - val_accuracy: 0.6598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 07:34:59.600701: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 20221115-070459/assets\n"
     ]
    }
   ],
   "source": [
    "#layer config 1 for spec\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=20\n",
    "filename=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = \"logs/scalars/\" + filename\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(\n",
    "    train_ds_spec,\n",
    "    validation_data=val_ds_spec,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "model.save(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 100, 200, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 100, 200, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 100, 200, 16)      4624      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 50, 100, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 50, 100, 8)        2056      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 50, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1280128   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,288,994\n",
      "Trainable params: 1,288,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "375/375 [==============================] - 372s 990ms/step - loss: 2.7292 - accuracy: 0.3660 - val_loss: 1.9253 - val_accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "375/375 [==============================] - 359s 958ms/step - loss: 1.6947 - accuracy: 0.5164 - val_loss: 1.5183 - val_accuracy: 0.5493\n",
      "Epoch 3/15\n",
      "375/375 [==============================] - 360s 959ms/step - loss: 1.4212 - accuracy: 0.5653 - val_loss: 1.3588 - val_accuracy: 0.5787\n",
      "Epoch 4/15\n",
      "375/375 [==============================] - 359s 957ms/step - loss: 1.2820 - accuracy: 0.5996 - val_loss: 1.2702 - val_accuracy: 0.6042\n",
      "Epoch 5/15\n",
      "375/375 [==============================] - 361s 963ms/step - loss: 1.1841 - accuracy: 0.6310 - val_loss: 1.2099 - val_accuracy: 0.6192\n",
      "Epoch 6/15\n",
      "375/375 [==============================] - 360s 960ms/step - loss: 1.1022 - accuracy: 0.6561 - val_loss: 1.1699 - val_accuracy: 0.6280\n",
      "Epoch 7/15\n",
      "375/375 [==============================] - 358s 955ms/step - loss: 1.0316 - accuracy: 0.6787 - val_loss: 1.1254 - val_accuracy: 0.6383\n",
      "Epoch 8/15\n",
      "375/375 [==============================] - 359s 956ms/step - loss: 0.9668 - accuracy: 0.6997 - val_loss: 1.1012 - val_accuracy: 0.6458\n",
      "Epoch 9/15\n",
      "375/375 [==============================] - 358s 955ms/step - loss: 0.9077 - accuracy: 0.7219 - val_loss: 1.0945 - val_accuracy: 0.6450\n",
      "Epoch 10/15\n",
      "375/375 [==============================] - 358s 956ms/step - loss: 0.8546 - accuracy: 0.7379 - val_loss: 1.0967 - val_accuracy: 0.6457\n",
      "Epoch 11/15\n",
      "375/375 [==============================] - 357s 952ms/step - loss: 0.8035 - accuracy: 0.7538 - val_loss: 1.1135 - val_accuracy: 0.6418\n",
      "Epoch 12/15\n",
      "375/375 [==============================] - 360s 961ms/step - loss: 0.7517 - accuracy: 0.7708 - val_loss: 1.1256 - val_accuracy: 0.6423\n",
      "Epoch 13/15\n",
      "375/375 [==============================] - 370s 986ms/step - loss: 0.7028 - accuracy: 0.7874 - val_loss: 1.1379 - val_accuracy: 0.6465\n",
      "Epoch 14/15\n",
      "375/375 [==============================] - 476s 1s/step - loss: 0.6570 - accuracy: 0.8038 - val_loss: 1.1564 - val_accuracy: 0.6492\n",
      "Epoch 15/15\n",
      "375/375 [==============================] - 387s 1s/step - loss: 0.6128 - accuracy: 0.8210 - val_loss: 1.1681 - val_accuracy: 0.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 09:52:02.374911: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 20221115-081927/assets\n"
     ]
    }
   ],
   "source": [
    "#layer config 2 for spec\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=15\n",
    "filename=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = \"logs/scalars/\" + filename\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(\n",
    "    train_ds_spec,\n",
    "    validation_data=val_ds_spec,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 100, 200, 3)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 100, 200, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 50, 100, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 50, 100, 32)       9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 25, 50, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 25, 50, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 12, 25, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               1228928   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,249,610\n",
      "Trainable params: 1,249,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 190s 504ms/step - loss: 2.8032 - accuracy: 0.3339 - val_loss: 1.9683 - val_accuracy: 0.4700\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 194s 516ms/step - loss: 1.7458 - accuracy: 0.4873 - val_loss: 1.5748 - val_accuracy: 0.4962\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 198s 527ms/step - loss: 1.4808 - accuracy: 0.5352 - val_loss: 1.4196 - val_accuracy: 0.5402\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 202s 539ms/step - loss: 1.3531 - accuracy: 0.5711 - val_loss: 1.3460 - val_accuracy: 0.5585\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 209s 556ms/step - loss: 1.2671 - accuracy: 0.5965 - val_loss: 1.2840 - val_accuracy: 0.5765\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 213s 569ms/step - loss: 1.1992 - accuracy: 0.6161 - val_loss: 1.2305 - val_accuracy: 0.5965\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 215s 575ms/step - loss: 1.1422 - accuracy: 0.6335 - val_loss: 1.1796 - val_accuracy: 0.6138\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 230s 614ms/step - loss: 1.0920 - accuracy: 0.6470 - val_loss: 1.1742 - val_accuracy: 0.6127\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 243s 648ms/step - loss: 1.0465 - accuracy: 0.6625 - val_loss: 1.1475 - val_accuracy: 0.6223\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 250s 668ms/step - loss: 1.0032 - accuracy: 0.6750 - val_loss: 1.1382 - val_accuracy: 0.6197\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 261s 696ms/step - loss: 0.9630 - accuracy: 0.6883 - val_loss: 1.1280 - val_accuracy: 0.6242\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 289s 771ms/step - loss: 0.9247 - accuracy: 0.7030 - val_loss: 1.1304 - val_accuracy: 0.6253\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 194s 518ms/step - loss: 0.8873 - accuracy: 0.7183 - val_loss: 1.1214 - val_accuracy: 0.6302\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 184s 490ms/step - loss: 0.8514 - accuracy: 0.7295 - val_loss: 1.1244 - val_accuracy: 0.6280\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 216s 577ms/step - loss: 0.8158 - accuracy: 0.7424 - val_loss: 1.0965 - val_accuracy: 0.6440\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 184s 490ms/step - loss: 0.7821 - accuracy: 0.7542 - val_loss: 1.0964 - val_accuracy: 0.6435\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 182s 485ms/step - loss: 0.7516 - accuracy: 0.7652 - val_loss: 1.0967 - val_accuracy: 0.6455\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 191s 509ms/step - loss: 0.7224 - accuracy: 0.7750 - val_loss: 1.0991 - val_accuracy: 0.6500\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 189s 503ms/step - loss: 0.6916 - accuracy: 0.7845 - val_loss: 1.0998 - val_accuracy: 0.6485\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 187s 498ms/step - loss: 0.6639 - accuracy: 0.7948 - val_loss: 1.1038 - val_accuracy: 0.6523\n",
      "INFO:tensorflow:Assets written to: 20221115-095203/assets\n"
     ]
    }
   ],
   "source": [
    "#layer config 3 for spec\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "\n",
    "filename=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=20\n",
    "\n",
    "logdir = \"logs/scalars/\" + filename\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(\n",
    "    train_ds_spec,\n",
    "    validation_data=val_ds_spec,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING CHROMATOGRAMS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 100, 200, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 100, 200, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 50, 100, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 100, 16)       2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 50, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 50, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 25, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1228928   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,237,626\n",
      "Trainable params: 1,237,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 99s 264ms/step - loss: 3.0489 - accuracy: 0.2193 - val_loss: 2.3544 - val_accuracy: 0.2947\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 89s 237ms/step - loss: 2.1460 - accuracy: 0.3062 - val_loss: 1.9854 - val_accuracy: 0.3268\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 88s 236ms/step - loss: 1.9366 - accuracy: 0.3351 - val_loss: 1.8863 - val_accuracy: 0.3472\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 89s 236ms/step - loss: 1.8561 - accuracy: 0.3587 - val_loss: 1.8372 - val_accuracy: 0.3600\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 89s 236ms/step - loss: 1.8015 - accuracy: 0.3771 - val_loss: 1.8067 - val_accuracy: 0.3680\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 83s 221ms/step - loss: 1.7555 - accuracy: 0.3929 - val_loss: 1.7881 - val_accuracy: 0.3748\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 82s 218ms/step - loss: 1.7143 - accuracy: 0.4084 - val_loss: 1.7750 - val_accuracy: 0.3793\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 82s 217ms/step - loss: 1.6771 - accuracy: 0.4245 - val_loss: 1.7689 - val_accuracy: 0.3837\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 82s 217ms/step - loss: 1.6405 - accuracy: 0.4387 - val_loss: 1.7646 - val_accuracy: 0.3852\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 84s 224ms/step - loss: 1.6045 - accuracy: 0.4505 - val_loss: 1.7612 - val_accuracy: 0.3853\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 82s 218ms/step - loss: 1.5664 - accuracy: 0.4678 - val_loss: 1.7618 - val_accuracy: 0.3838\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 84s 224ms/step - loss: 1.5272 - accuracy: 0.4832 - val_loss: 1.7686 - val_accuracy: 0.3803\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 91s 242ms/step - loss: 1.4861 - accuracy: 0.5021 - val_loss: 1.7734 - val_accuracy: 0.3823\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 90s 239ms/step - loss: 1.4415 - accuracy: 0.5186 - val_loss: 1.7791 - val_accuracy: 0.3903\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 1.3957 - accuracy: 0.5360 - val_loss: 1.7974 - val_accuracy: 0.3860\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 1.3493 - accuracy: 0.5546 - val_loss: 1.8189 - val_accuracy: 0.3855\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 1.3027 - accuracy: 0.5718 - val_loss: 1.8509 - val_accuracy: 0.3857\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 90s 239ms/step - loss: 1.2552 - accuracy: 0.5885 - val_loss: 1.8787 - val_accuracy: 0.3903\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 90s 239ms/step - loss: 1.2079 - accuracy: 0.6084 - val_loss: 1.9292 - val_accuracy: 0.3867\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 89s 238ms/step - loss: 1.1623 - accuracy: 0.6239 - val_loss: 1.9666 - val_accuracy: 0.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 08:06:57.755999: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 20221115-073750/assets\n"
     ]
    }
   ],
   "source": [
    "#layer config 1 for chroma\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=20\n",
    "filename=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = \"logs/scalars/\" + filename\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(\n",
    "    train_ds_chroma,\n",
    "    validation_data=val_ds_chroma,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "\n",
    "model.save(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer config 2 for chroma\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 4, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=20\n",
    "filename=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "logdir = \"logs/scalars/\" + filename\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(\n",
    "    train_ds_chroma,\n",
    "    validation_data=val_ds_chroma,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer config 3 for chroma\n",
    "num_classes = len(class_names)\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),s\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes,kernel_regularizer=l2(0.1),activation = \"linear\")\n",
    "])\n",
    "#hyperparams\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "\n",
    "filename=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "epochs=20\n",
    "\n",
    "logdir = \"logs/scalars/\" + filename\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(\n",
    "    train_ds_chroma,\n",
    "    validation_data=val_ds_chroma,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    )\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ai_ml_nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75f149aabefc45f596bad3ecd1cce999665dc47c609d2b6ed1c0c06088326543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
